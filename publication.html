s<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="index, follow">

    <title>4DV LAB</title>
    <meta name="description" content="">
    <link rel="alternate" type="application/rss+xml" href="/feed.xml">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/css/main.css" rel='stylesheet' type='text/css'>

    <!-- Google Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Nunito:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic' rel='stylesheet'
        type='text/css'>

    <!-- Favicon -->
    <!-- <link rel="shortcut icon" href="/imgs/logo.png"> -->
</head>

<body data-spy="scroll" data-offset="80" data-target=".scrollspy" id="top" style="background-color: black;">
    <div class="navigation"></div>
    <div class="news top-container">
        <div class="container-fluid">
            <div class="post">
                
                <h2><font color="white">Selected Papers</font></h2>
                <hr />

                <!-- ICCV 2022 jq,lyh -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/seemore.png">
                        </div>

                        <h4 class="media-heading" style="color: white;">
                            See More and Know More: Zero-shot Point Cloud Segmentation via Multi-modal Visual Data<br>
                            <small>Yuhang Lu, Qi Jiang, Runnan Chen, Yuenan Hou, Xinge Zhu, Yuexin Ma</small>
                        </h4>

                        <small><font color="white">Accepted by</font>
                            <strong>
                                <font color="red">ICCV 2023</font>
                            </strong>
                            <br>
                            <!-- <a href="https://github.com/tb2-sy/TSP-Transformer" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/pdf/2307.10782" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>


                <!-- ICCV 2023 xyt,cps,yyc -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/hucenlife.png">
                        </div>

                        <h4 class="media-heading">
                            Human-centric Scene Understanding in 3D Large-scale Scenarios<br>
                            <small>Yiteng Xu, Peishan Cong, Yichen Yao, Runnan Chen, Yuenan Hou, Xinge Zhu, Xuming He, Jingyi Yu, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICCV 2023</font>
                            </strong>
                            <br>
                            <!-- <a href="https://neuralcarver.github.io/michelangelo/" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/pdf/2307.14392" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>

                <!-- ICRA 2023 yht -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/yht.png">
                        </div>

                        <h4 class="media-heading">
                            One Training for Multiple Deployments: Polar-based Adaptive BEV Perception for Autonomous Driving <br>
                            <small>Huitong Yang, Xuyang Bai, Xinge Zhu, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICRA 2023</font>
                            </strong>
                            <br>
                            <!-- <a href="https://neuralcarver.github.io/michelangelo/" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/abs/2212.00244" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>

                <!-- TVCG 2023 rym,zcf -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/Lip.png">
                        </div>

                        <h4 class="media-heading">
                            LiDAR-aid Inertial Poser: Large-scale Human Motion Capture by Sparse Inertial and LiDAR Sensors <br>
                            <small>Yiming Ren, Chengfeng Zhao, Yannan He, Peishan Cong, Han Liang, Jingyi Yu, Lan Xu, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">TVCG 2023</font>
                            </strong>
                            <br>
                            <!-- <a href="https://github.com/zyhbili/LivelySpeaker" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/abs/2205.15410" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>


                <!-- AAAI 2023 pxd -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/cl3d.png">
                        </div>

                        <h4 class="media-heading">
                            CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection <br>
                            <small>Xidong Peng, Xinge Zhu, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">AAAI 2023</font>
                            </strong>
                            <br>
                            <!-- <a href="https://bluestyle97.github.io/dream3d/" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/abs/2212.00244" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>

                <!-- AAAI 2023 xyt,cps -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/fusionpose.png">
                        </div>

                        <h4 class="media-heading">
                            Weakly Supervised 3D Multi-person Pose Estimation for Large-scale Scenes based on Monocular Camera and Single LiDAR<br>
                            <small>Peishan Cong, Yiteng Xu, Yiming Ren, Juze Zhang, Lan Xu, Jingya Wang, Jingyi Yu, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">AAAI 2023</font>
                            </strong>
                            <br>
                            <!-- <a href="https://github.com/svip-lab/WeakSVR" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/abs/2211.16951" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>

                <!-- CVPR 2022 cps -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/stcrowd.png">
                        </div>

                        <h4 class="media-heading">
                            STCrowd: A Multimodal Dataset for Pedestrian Perception in Crowded Scenes <br>
                            <small>Peishan Cong, Xinge Zhu, Feng Qiao, Yiming Ren, Xidong Peng, Yuenan Hou, Lan Xu, Ruigang Yang, Dinesh Manocha, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">CVPR 2022</font>
                            </strong>
                            <br>
                            <!-- <a href="https://github.com/svip-lab/PlaneDepth" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/abs/2204.01026" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>

                <!-- ICME 2022 rym -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/completion.PNG">
                        </div>

                        <h4 class="media-heading">
                            Self-supervised Point Cloud Completion on Real Traffic Scenes via Scene-concerned Bottom-up Mechanism <br>
                            <small>Yiming Ren, Peishan Cong, Xinge Zhu, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICME 2022</font>
                            </strong>
                            <br>
                            <!-- <a href="https://github.com/svip-lab/PlaneDepth" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/abs/2203.10569" target="_blank" style="color: #990000">[Paper]</a>
                        </small>
                    </div>
                </div>
                
                <!-- WACV 2022 Zhi -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/wacv.png">
                        </div>

                        <h4 class="media-heading">
                            SIDE: Center-based Stereo 3D Detector with Structure-awareInstance Depth Estimation <br>
                            <small>Xidong Peng, Xinge Zhu, Tai Wang, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">WACV 2022</font>
                            </strong>
                            <br>
                            <!-- <a href="https://shenhanqian.github.io/ds-nerf" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/abs/2108.09663" target="_blank" style="color: #990000">[Paper]</a>
                            <!-- <a href="https://youtu.be/2qk4WOO8YMw" target="_blank" style="color: #990000">[Video]</a> -->
                            <!-- <a href="https://github.com/zyhbili/Dual-Space-NeRF" target="_blank" style="color: #990000">[Code]</a> -->
                        </small>
                    </div>
                </div>

                <!-- ICME 2021 cps -->
                <div class="media">
                    <div class="media-body">
                        <div class="col-xs-3">
                            <img src="imgs/paper_fig/icme2021.png">
                        </div>

                        <h4 class="media-heading">
                            Input-Output Balanced Framework for Long-tailed LiDAR Semantic Segmentation <br>
                            <small>Peishan Cong, Xinge Zhu, Yuexin Ma</small>
                        </h4>

                        <small>Accepted by
                            <strong>
                                <font color="red">ICME 2021</font>
                            </strong>
                            <br>
                            <!-- <a href="https://shenhanqian.github.io/unif" target="_blank" style="color: #990000">[Project]</a> -->
                            <a href="https://arxiv.org/abs/2103.14269" target="_blank" style="color: #990000">[Paper]</a>
                            <!-- <a href="https://youtu.be/2w4sYMLFHKM" target="_blank" style="color: #990000">[Video]</a>
                            <a href="https://github.com/ShenhanQian/UNIF" target="_blank" style="color: #990000">[Code]</a> -->
                        </small>
                    </div>
                </div>
                <hr />

            </div>
        </div>
    </div>


    <div class="footer"></div>
    <script src="/js/jquery.min.js"></script>
    <script src="/js/all.min.js"></script>

    <script>
        $(document).ready(function () {
            $(".footer").load("/common/footer.html");
            $(".navigation").load("/common/navigation.html");
        });
    </script>
</body>

</html>
